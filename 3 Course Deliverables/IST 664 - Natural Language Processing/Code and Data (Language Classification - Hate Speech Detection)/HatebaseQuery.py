# -*- coding: utf-8 -*-
"""HatebaseQuery.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sK1aZCPAUCHAGwfZvYohHf3_3yl55qtr
"""

import requests
import json
import csv

response_auth = requests.post('https://api.hatebase.org/4-4/authenticate',data={'api_key':'XXXXXXXXXXkeyXXXXXXXXXX'})
print(response_auth.status_code)

data_query = {
    'token': response.json()['result']['token'],
    'page': 1
}
number_of_pages = 1
eng_terms = []
while data_query['page'] <= number_of_pages:
  response_query = requests.post('https://api.hatebase.org/4-4/get_vocabulary', data=data_query)
  print(str(data_query['page'])+':\t',response_query.status_code)
  page_terms = [(result['term'], result['average_offensiveness']) for result in response_query.json()['result'] if result['language']=='eng']
  eng_terms.extend(page_terms)
  if data_query['page'] == 1:
    number_of_pages = response_query.json()['number_of_pages']
  data_query['page'] += 1

print(eng_terms)

with open('hatebase.csv', 'w') as outfile:
  csv_outfile = csv.writer(outfile)
  csv_outfile.writerow(['term','average_offensiveness'])
  for term in eng_terms:
    csv_outfile.writerow(list(term))